{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb79Eqr0/rxRCwF/vXPLnn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanskriti111-j/Gen-AI-LLMs/blob/main/Finetuning_LLM_for_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5Dql1a5TOx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "pYbH_5reTOMl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LJH2_wRTCuU",
        "outputId": "79c72fa8-ab0a-4e78-c914-7b83ac0ab044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import ssl\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Create an unverified SSL context\n",
        "    ssl_context = ssl._create_unverified_context()\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the file in pandas df"
      ],
      "metadata": {
        "id": "abWdmYd9UDLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "HDfNSFxsUFVc",
        "outputId": "fe6d4cd3-0047-4622-c7d0-e79a48188c6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b53a8c00-db90-461d-a8f4-0d55943007b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b53a8c00-db90-461d-a8f4-0d55943007b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b53a8c00-db90-461d-a8f4-0d55943007b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b53a8c00-db90-461d-a8f4-0d55943007b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2e42ff3e-72ec-4528-beb2-b990a73a235c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e42ff3e-72ec-4528-beb2-b990a73a235c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2e42ff3e-72ec-4528-beb2-b990a73a235c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_57c401fd-9172-48b3-8fc1-94b0a970403c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_57c401fd-9172-48b3-8fc1-94b0a970403c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check distirbution of files"
      ],
      "metadata": {
        "id": "l1a6pY0tUNOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I4KFms1UJqH",
        "outputId": "f23e1f8d-5d41-49fa-bf92-793c8cea64d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we subsample the dataset so that it contain 747 items of each instance"
      ],
      "metadata": {
        "id": "yrHyei_JUhcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        "\n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hzqdvIpUn45",
        "outputId": "cd354ba0-2177-401c-90f1-6c45802e539c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert string class label ham,spam to integer class label 0 or 1"
      ],
      "metadata": {
        "id": "UOOWZdgxU8H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ],
      "metadata": {
        "id": "F0C2P7AVU1WO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting dataset for training, validation, testing"
      ],
      "metadata": {
        "id": "IdFzmxISVQBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# Test size is implied to be 0.2 as the remainder\n"
      ],
      "metadata": {
        "id": "ulazPRqwVK0o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df))\n",
        "print(len(validation_df))\n",
        "print(len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leup4pO3X_IG",
        "outputId": "570eb597-0888-4f6a-cb16-3c540259ef3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1045\n",
            "149\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "save the dataset to csv file"
      ],
      "metadata": {
        "id": "3opYDLl2YDdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "ZlyTO7c7YFto"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding Dataloaders"
      ],
      "metadata": {
        "id": "iBq-e7tfYalB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate uniform size text chunks we have two options:\n",
        "\n",
        "(1) Truncate all messages to the length of the shortest message in the dataset or batch.\n",
        "\n",
        "(2) Pad all messages to the length of the longest message in the dataset or batch.\n",
        "\n",
        "Option 1 is computationally cheaper, but it may result in significant information loss if shorter messages are much smaller than the average or longest messages, potentially reducing model performance.\n",
        "\n",
        "So, we opt for the second option, which preserves the entire content of all messages.\n",
        "\n",
        "To implement option 2, where all messages are padded to the length of the longest message in the dataset, we add padding tokens to all shorter messages.\n",
        "\n",
        "For this purpose, we use \"<|endoftext|>\" as a padding token.\n",
        "\n",
        "We define the SpamDataset class.\n",
        "\n",
        "This SpamDataset class handles several key tasks: it identifies the longest sequence in the training dataset, encodes the text messages, and ensures that all other sequences are padded with a padding token to match the length of the longest sequence."
      ],
      "metadata": {
        "id": "PVbgaN11Yeib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "\n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length"
      ],
      "metadata": {
        "id": "lteJlYJXYA0g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Pre-tokenize texts\n",
        "\n",
        "Step 2: Truncate sequences if they are longer than max_length\n",
        "\n",
        "Step 3: Pad sequences to the longest sequence"
      ],
      "metadata": {
        "id": "2cVskdxrZmE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "mQus3vd2givx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtDCpFBqZm_f",
        "outputId": "f29ed13a-a954-482e-97f3-2e9d798d5ebe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code outputs 120, showing that the longest sequence contains no more than 120 tokens, a common length for text messages.\n",
        "\n",
        "Next, we pad the validation and test sets to match the length of the longest training sequence.\n",
        "\n",
        "Any validation and test set samples exceeding the length of the longest training example are truncated using encoded_text[:self.max_length] ."
      ],
      "metadata": {
        "id": "N6Cb0zC2gsiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(test_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuJ3oCPFgr9W",
        "outputId": "8cbd8b1f-708a-4535-dc1d-40022f8f058e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "choosing a batch size of 8, each batch will consist of 8 training examples of length 120 and the corresponding class label of each example."
      ],
      "metadata": {
        "id": "mIg983LWheiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "R15rP9AfhkF2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBnvGLFaheP8",
        "outputId": "af00c1dd-37a1-4ed3-9339-3fe02be45a54"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUFHT-o0h2t5",
        "outputId": "b74ce52c-c1f4-4343-e7ef-301a83c6668d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing a model with pre trained weights"
      ],
      "metadata": {
        "id": "tYP7LYNih_0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        ")"
      ],
      "metadata": {
        "id": "Jkr3VX_Ph-Lh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we import the download_and_load_gpt function from the gpt_download3.py file we downloaded earlier.\n",
        "\n",
        "Furthermore, we also reuse the GPTModel class and load_weights_into_gpt function from chapter 5 to load the downloaded weights into the GPT model:\n",
        "\n",
        "\n",
        "[ ]\n"
      ],
      "metadata": {
        "id": "aor9UBWRicgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "svsMKioLi6iN",
        "outputId": "6cecfc78-dd20-4266-abd3-4f6b4fe265c2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2841570116.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGPTModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emb_dim\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emb_dim\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}"
      ],
      "metadata": {
        "id": "CKnke6MkkFNl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # Use a placeholder for TransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        # Use a placeholder for LayerNorm\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # A simple placeholder\n",
        "\n",
        "    def forward(self, x):\n",
        "        # This block does nothing and just returns its input.\n",
        "        return x\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, normalized_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        # The parameters here are just to mimic the LayerNorm interface.\n",
        "\n",
        "    def forward(self, x):\n",
        "        # This layer does nothing and just returns its input.\n",
        "        return x"
      ],
      "metadata": {
        "id": "ShvbvnqKkGe8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
        "            GELU(), ## Activation\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "1s-T30SZkcAt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        # 2*4*768\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "        # 2*4*768"
      ],
      "metadata": {
        "id": "jxtn6I3skdTU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "FgHUg_bYktpy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "6V3x5zDTlbGI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "oXqVGkgXlTej"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "    ###Input batch:\n",
        " ###tensor([[6109, 3626, 6100,  345],\n",
        "        ##[6109, 1110, 6622,  257]])\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "ZwZGnNlRnHiC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "\n",
        "from gpt_download3 import download_and_load_gpt2\n",
        "\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIjtUP7Siavv",
        "outputId": "6ddad7a8-3695-472c-cd0e-3f28c5f9ec6d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n"
      ],
      "metadata": {
        "id": "3cb1Q8oknqGX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"I am thinking\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZijyVa4llit",
        "outputId": "a2b5f386-e542-499b-edb6-b505262c2714"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am thinking of a way to make it easier for people to get a job. I am thinking of a way to make it easier for people to get a job.\n",
            "\n",
            "I am\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "before we start finetuning the model as a spam classifier, let's see if the model can perhaps already classify spam messages by by prompting it with instructions:"
      ],
      "metadata": {
        "id": "FSE591f5n3eK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHVkkXfHn4Qa",
        "outputId": "c6c43d9a-7d4c-4f5b-b0a4-44f56f35edea"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "our model is not able to classify right now"
      ],
      "metadata": {
        "id": "1ao3S5IwoIYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification head"
      ],
      "metadata": {
        "id": "4zfhtFJNoMxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "we modify the pretrained large language model to prepare it for classification-finetuning.\n",
        "\n",
        "\n",
        "We replace the original output layer, which maps the hidden representation to a vocabulary of 50,257, with a smaller output layer that maps to two classes: 0 (\"not spam\") and 1 (\"spam\"),"
      ],
      "metadata": {
        "id": "DUvHFSinoWuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FZhSIieohl-",
        "outputId": "8eae8d00-31f2-41e4-abe4-591cce3e0243"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The GPTModel consists of embedding layers followed by 12 identical transformer blocks (only the last block is shown for brevity), followed by a final LayerNorm and the output layer, out_head."
      ],
      "metadata": {
        "id": "cXLSdIgsotno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we replace the out_head with a new output layer,which will ahve 2 output head 0,1 for spam and ham(non-spam) that we will finetune.\n",
        "\n",
        "To get the model ready for classification-finetuning, we first freeze the model, meaning that we make all layers non-trainable:"
      ],
      "metadata": {
        "id": "uUNUMnGQo1ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "goTVgl3GolBg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
      ],
      "metadata": {
        "id": "gnGVHNB2pF7r"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We replaced the output layer (model.out_head), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)."
      ],
      "metadata": {
        "id": "13Hw_218pKfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means we can also use the same code to work with the larger GPT-2 model variants.\n",
        "\n",
        "This new model.out_head output layer has its requires_grad attribute set to True by default, which means that it's the only layer in the model that will be updated during training.\n",
        "\n",
        "This new model.out_head output layer has its requires_grad attribute set to True by default, which means that it's the only layer in the model that will be updated during training.\n",
        "\n",
        "\n",
        "[ ]\n"
      ],
      "metadata": {
        "id": "1_fTzn-YptMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, we configure the last transformer block and the final LayerNorm module, which connects this block to the output layer, to be trainable"
      ],
      "metadata": {
        "id": "O_pH3rn9pyrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "6dHvV4yZpJ4w"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In particular, we will focus on the last row corresponding to the last output token"
      ],
      "metadata": {
        "id": "GwU-nSZZqLLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine the classification accuracy, we apply the argmax-based prediction code to all examples in the dataset and calculate the proportion of correct predictions by defining a calc_accuracy_loader function:"
      ],
      "metadata": {
        "id": "FCUJI18l5wsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples"
      ],
      "metadata": {
        "id": "Xz3CY-zI5wan"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accordingly, the calc_loss_batch function remains the same as in earlier, with one adjustment: we focus on optimizing only the last token, model(input_batch)[:, -1, :], rather than all tokens, model(input_batch):"
      ],
      "metadata": {
        "id": "9B4u-FXo6Lwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
        "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#print(f\"Running on {device} device.\")\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GiT76zK65n8",
        "outputId": "cf176133-b9b4-4ca5-be04-aed0eb91f443"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7bca24efdf70>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Tl-FWihLp7b2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the calc_loss_batch function to compute the loss for a single batch obtained from the previously defined data loaders. To calculate the loss for all batches in a data loader, we define the calc_loss_loader function"
      ],
      "metadata": {
        "id": "G4uXAQei6Zmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "DOxTtEKt6ZVe"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we now compute the initial loss for each data set:"
      ],
      "metadata": {
        "id": "uorP-GVM6p6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)"
      ],
      "metadata": {
        "id": "9j3iYKlW6U88"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune the model on Supervised data"
      ],
      "metadata": {
        "id": "C_gS83Gc7V7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " we define and use the training function to finetune the pretrained LLM and improve its spam classification accuracy.\n",
        "\n",
        " The training loop is the same overall training loop we used earlier, with the only difference being that we calculate the classification accuracy instead of generating a sample text for evaluating the model.\n",
        "\n",
        "The training function also closely mirrors the train_model_simple function used for pretraining the model earlier.\n",
        "\n",
        "The only two distinctions are that we now track the number of training examples seen (examples_seen) instead of the number of tokens, and we calculate the accuracy after each epoch instead of printing a sample text:\n",
        "\n",
        "Step 1: Set model to training mode\n",
        "\n",
        "Step 2: Reset loss gradients from previous batch iteration\n",
        "\n",
        "Step 3: Calculate loss gradients\n",
        "\n",
        "Step 4: Update model weights using loss gradients\n",
        "\n",
        "Step 5: New: track examples instead of tokens\n",
        "\n",
        "Step 6: Optional evaluation step\n",
        "\n",
        "Step 7: Calculate accuracy after each epoch\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bGpEDeGu7mZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # Initialize lists to track losses and examples seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ],
      "metadata": {
        "id": "zUoFLuHd7aL_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ],
      "metadata": {
        "id": "an7GT3Q37_v-"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we initialize the optimizer, set the number of training epochs, and initiate the training using the train_classifier_simple function."
      ],
      "metadata": {
        "id": "IMzZXsVS8G5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZO81J5AC8Gwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ill5I0nX8Gel",
        "outputId": "c9bb8c87-5a11-43fe-a9ca-24947a952130"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
            "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
            "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
            "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
            "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
            "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
            "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
            "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
            "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
            "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
            "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training completed in 57.17 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SKJdvEXiLy7f"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "-FlpjOrHL2ua",
        "outputId": "c5c26f45-2331-471d-8c2f-5e14f52b9a85"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the same plot_values function, let's now also plot the classification accuracies:\n",
        "\n"
      ],
      "metadata": {
        "id": "KSrl-_mDL8Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "LDv3tdrtL9TD",
        "outputId": "c0846fcd-99f4-45ba-b3be-b86fbad7be96"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the accuracy plot in figure 6.17, the model achieves a relatively high training and validation accuracy after epochs 4 and 5.\n",
        "\n",
        "However, it's important to note that we previously set eval_iter=5 when using the train_classifier_simple function, which means our estimations of training and validation performance were based on only 5 batches for efficiency during training.\n",
        "\n",
        "Now, we will calculate the performance metrics for the training, validation, and test sets across the entire dataset by running the following code, this time without defining the eval_iter value:"
      ],
      "metadata": {
        "id": "twm4_mu1MGHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt2CJHtAMHGb",
        "outputId": "6705aae3-ae3b-4162-ad88-98f7ffbbb2ea"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 97.21%\n",
            "Validation accuracy: 97.32%\n",
            "Test accuracy: 95.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the LLM as a spam classifier"
      ],
      "metadata": {
        "id": "mMLLFxxgMQiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's use the finetuned GPT-based spam classification model.\n",
        "\n",
        "The following classify_review function follows data preprocessing steps similar to those we used in the SpamDataset implemented earlier in this chapter.\n",
        "\n",
        "And then, after processing text into token IDs, the function uses the model to predict an integer class label, similar to what we have implemented earlier, and then returns the corresponding class name:\n",
        "\n",
        "Step 1: Prepare inputs to the model\n",
        "\n",
        "Step 2: Truncate sequences if they too long\n",
        "\n",
        "Step 3: Pad sequences to the longest sequence\n",
        "\n",
        "Step 4: Add batch dimension\n",
        "\n",
        "Step 5: Model inference without gradient tracking\n",
        "\n",
        "Step 6: Logits of the last output token\n",
        "\n",
        "Step 7: Return the classified result"
      ],
      "metadata": {
        "id": "j3lShlenMXy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
        "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"spam\" if predicted_label == 1 else \"not spam\""
      ],
      "metadata": {
        "id": "KibnLppyMci4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now review it on a sample text"
      ],
      "metadata": {
        "id": "Nsr_AIQaMgDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0dQE4ZEMkZY",
        "outputId": "09a1030a-e470-4125-ad91-5d11d9050188"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "    \"You are the lucky person who won this opportuinity\"\n",
        "\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl3PCt3eMpPV",
        "outputId": "bf505217-2472-458f-ef80-90841acf493a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, here, the model makes a correct prediction and returns a \"not spam\" label."
      ],
      "metadata": {
        "id": "XrR1F93BMw1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's save the model in case we want to reuse the model later without having to train it again using the torch.save method\n",
        "\n",
        "\n",
        "[ ]\n"
      ],
      "metadata": {
        "id": "JzH-8LF4M03Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")\n"
      ],
      "metadata": {
        "id": "l4B3OG-MMxw-"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once saved, the model can be loaded as follows:"
      ],
      "metadata": {
        "id": "6TO6oqRQM6Gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Evj5MxEfM_Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = torch.load(\"review_classifier.pth\")\n",
        "model.load_state_dict(model_state_dict)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKyaaN1qPW6r",
        "outputId": "aa3f3c56-1a82-4c1a-a569-4950eab08f82"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}